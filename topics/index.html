<!doctype html> <!-- Minimal Mistakes Jekyll Theme 4.16.4 by Michael Rose Copyright 2013-2019 Michael Rose - mademistakes.com | @mmistakes Free for personal and commercial use under the MIT license https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE --> <html lang=en > <meta charset=UTF-8 > <meta name=viewport  content="width=device-width, initial-scale=1"> <link rel=stylesheet  href="/mpags-high-performance-computing/css/franklin.css"> <link rel=stylesheet  href="/mpags-high-performance-computing/css/minimal-mistakes.css"> <link rel=stylesheet  href="/mpags-high-performance-computing/css/adjust.css"> <link rel=icon  href="/mpags-high-performance-computing/assets/favicon.png"> <!--[if IE ]> <style> /* old IE unsupported flexbox fixes */ .greedy-nav .site-title { padding-right: 3em; } .greedy-nav button { position: absolute; top: 0; right: 0; height: 100%; } </style> <![endif]--> <title>Topics</title> <body class=layout--single > <div class=masthead > <div class=masthead__inner-wrap > <div class=masthead__menu > <nav id=site-nav  class=greedy-nav > <a class=site-title  href="/mpags-high-performance-computing/">High Performance Computing in Julia</a> <ul class=visible-links > <li class=masthead__menu-item ><a href="/mpags-high-performance-computing/overview/" >Overview</a> <li class=masthead__menu-item ><a href="/mpags-high-performance-computing/topics/" >Topics</a> <li class=masthead__menu-item ><a href="/mpags-high-performance-computing/timetable/" >Timetable</a> <li class=masthead__menu-item ><a href="/mpags-high-performance-computing/resources/" >Resources</a> </ul> <button class="greedy-nav__toggle hidden" type=button > <span class=visually-hidden >Toggle menu</span> <div class=navicon ></div> </button> <ul class="hidden-links hidden"></ul> </nav> </div> </div> </div> <div class=initial-content > <div id=main  role=main > <div class="sidebar sticky"> <div itemscope itemtype="https://schema.org/Person"> <div class=author__avatar > <img src="/mpags-high-performance-computing/assets/minimal-mistakes/pp.jpg" alt="Jamie Mair" itemprop=image > </div> <div class=author__content > <h3 class=author__name  itemprop=name >Jamie Mair</h3> <p class=author__bio  itemprop=description >Final-year PhD Student studying Machine Learning in Physics at the University of Nottingham</p> </div> <div class=author__urls-wrapper > <button class="btn btn--inverse">Follow</button> <ul class="author__urls social-icons"> <li itemprop=homeLocation  itemscope itemtype="https://schema.org/Place"> <i class="fas fa-fw fa-map-marker-alt" aria-hidden=true ></i> <span itemprop=name >Nottingham, UK</span> <li><a href="https://github.com/JamieMair" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden=true ></i> GitHub</a> </ul> </div> </div> </div> <div class=franklin-content ><h1 id=topics ><a href="#topics" class=header-anchor >Topics</a></h1> <div class=franklin-toc ><ol><li><a href="#introduction_to_software_and_hardware">Introduction to Software and Hardware</a><li><a href="#julia_crash_course">Julia Crash Course</a><li><a href="#measuring_performance">Measuring Performance</a><li><a href="#optimising_serial_code">Optimising Serial Code</a><li><a href="#professional_research_software_engineering">Professional Research Software Engineering</a><li><a href="#introduction_to_parallel_programming">Introduction to Parallel Programming</a><li><a href="#multithreading_multiprocessing">Multithreading &amp; Multiprocessing</a><li><a href="#gpgpu_programming">GPGPU Programming</a></ol></div> <h2 id=introduction_to_software_and_hardware ><a href="#introduction_to_software_and_hardware" class=header-anchor >Introduction to Software and Hardware</a></h2> <p>This module will start with a description of modern hardware and software, as many students do not come from a Computer Science background. We aim to teach the student the basic architecture of a modern system, describing in detail parts such as the CPU, memory and co-processors like Graphics Processing Units &#40;GPUs&#41;. We do this to ground future discussions of optimisations with a physical model of the computing system one is optimising for. Additionally, we will dive into the basics of software on a computing system, discussing what an operating system is, and how source code is transformed into machine code which can run on the system via the use of compilers. Using the knowledge of this section we will cover the taxonomy of the features of modern programming languages, and their relation to high performance code.</p> <h2 id=julia_crash_course ><a href="#julia_crash_course" class=header-anchor >Julia Crash Course</a></h2> <p>As we are not expecting any students taking this course to have experience with the Julia programming language, we will cover a quick crash course into the syntax of the language and give students a mental model of how the language functions so that they can understand the code examples throughout the module. This course is grounded in practical examples, given and assessed using Julia. While the concepts in this module are certainly applicable to other languages, Julia has been chosen for this course as it has the lowest barrier to entry for writing high performance, parallel code &#40;including GPU programming&#41;.</p> <h2 id=measuring_performance ><a href="#measuring_performance" class=header-anchor >Measuring Performance</a></h2> <p>Optimisation is fairly useless without the ability to measure the impact of your changes. Benchmarking forms a core part of high performance computing, and this section will cover how to efficiently measure the run-time of your code, while we begin to understand what makes code run slowly. We will cover basic benchmarking techniques, such as timing, as well as more advanced techniques, such as profiling, to understand where to focus our time and effort when optimising. Additionally, we will touch on the theory of computational complexity to explain how the performance of an algorithm scales with the problem size.</p> <h2 id=optimising_serial_code ><a href="#optimising_serial_code" class=header-anchor >Optimising Serial Code</a></h2> <p>Here, we will focus on trying to get a given algorithm to execute as quickly, or efficiently, as possible on some given hardware. We will touch on lower-level optimisation details such as memory locality, stack vs heap memory and non-branching programming. The aim of this section is to write simple, yet fast, code to run as quickly as possible. We will also talk about Julia specific techniques to increase performance &#40;or rather, avoid bad performance&#41;.</p> <h2 id=professional_research_software_engineering ><a href="#professional_research_software_engineering" class=header-anchor >Professional Research Software Engineering</a></h2> <p>Almost every area of research is increasingly relying on computational techniques to push their fields forward, through large data processing, simulation or machine learning techniques. Often times, techniques yielded from experience with software engineering in industry are often neglected during research as they aren&#39;t seen as a high priority. However, software engineering has many best practices and techniques used to produce <strong>high quality</strong> and <strong>error-free</strong> code, without much, if any, loss in productivity. This part of the module aims to convey the advantages of using techniques such as version control, unit testing and documentation to increase the quality of your research, and provide a base to push the field forwards at an accelerated pace. Along with the techniques mentioned, we will also have a large focus on reproducibility and open science, particularly applicable to researchers. These techniques will be emphasised throughout the module and students will get a chance to practice them during the assignments.</p> <h2 id=introduction_to_parallel_programming ><a href="#introduction_to_parallel_programming" class=header-anchor >Introduction to Parallel Programming</a></h2> <p>Here, we will introduce the theory of parallel computing and provide a framework to analyse the ability of an algorithm to be accelerated using parallel processing via the use of Directed Acyclical Graphs &#40;DAGs&#41;. The theory introduced in this section will help frame the practical applications of parallel computing to any given task, while also giving theoretical devices to aid parallelising algorithms via the use of <em>maps</em> and <em>reductions</em>. On the practical side of things, we will talk about <strong>race conditions</strong> which are common pitfalls new students make when doing parallel computing.</p> <h2 id=multithreading_multiprocessing ><a href="#multithreading_multiprocessing" class=header-anchor >Multithreading &amp; Multiprocessing</a></h2> <p>Multithreading is the easiest and most common paradigm one can use to parallelise one&#39;s code. We will start by discussing the advantages and disadvantages of using multithreading, as well as giving many practical examples of how to use multithreading in your code via the discussion of an <em>embarrassingly-parallel</em> problem. Next, we will discuss multiprocessing, which can be used to scale up parallel processing across an entire cluster. We will give examples of how multiprocessing can be achieved in Julia and show examples of how to scale up execution to an entire High Performance Cluster.</p> <h2 id=gpgpu_programming ><a href="#gpgpu_programming" class=header-anchor >GPGPU Programming</a></h2> <p>The end of the module will centre around <em>General Purpose Graphics Processing Unit</em> &#40;GPGPU&#41; programming. GPUs are incredible devices with the ability to perform tens of thousands of operations in parallel. Programming for these devices has had a notoriously high barrier to entry until only recently. Julia provides users the ability to write native Julia code that can be executed directly on the GPU, increasing the flexibility and re-useability of the code for execution on many different devices. In this section, we will talk about the theory of GPU computing and give students an idea of what workloads can be accelerated by using a GPU, along with the limitations. Further, we will give students the opportunity to use the GPU via high-level abstractions and even write their own GPU kernels &#40;programs that run on the GPU&#41;, all in Julia.</p> <div class=page-foot > <a href="http://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA 4.0</a> Jamie Mair. Last modified: June 28, 2023. Website built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a> and the <a href="https://julialang.org">Julia programming language</a>. </div> </div> </div> </div> <div class=page__footer > <footer> <div class=page__footer-follow > <ul class=social-icons > <li><strong>Follow:</strong> <li><a href="https://github.com/JamieMair" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden=true ></i> GitHub</a> </ul> </div> <div class=page__footer-copyright >&copy; Jamie Mair. Powered by <a href="https://github.com/tlienart/Franklin.jl">Franklin</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel=nofollow >Minimal Mistakes</a>.</div> </footer> </div> <script src="/mpags-high-performance-computing/libs/minimal-mistakes/main.min.js"></script> <script defer src="https://use.fontawesome.com/releases/v5.8.2/js/all.js" integrity="sha384-DJ25uNYET2XCl5ZF++U8eNxPWqcKohUUBUpKGlNLMchM7q4Wjg2CUpjHLaL8yYPH" crossorigin=anonymous ></script>